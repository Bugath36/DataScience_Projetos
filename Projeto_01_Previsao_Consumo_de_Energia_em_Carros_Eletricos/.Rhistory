#
library(dplyr)
library(kim)
library(caret)
# Carregando o Dataset
dados <- as.data.frame(read_csv(name = 'dados_ajustados', head = TRUE,
dirname = 'dados' ))
dim(dados)
dados <- dados[, 5:26]
dim(dados)
str(dados)
dados$Freios <- as.factor(dados$Freios)
dados$Cambio <- as.factor(dados$Cambio)
dados$NumAssentos <- as.factor(dados$NumAssentos)
dados$NumeroPortas <- as.factor(dados$NumeroPortas)
str(dados)
View(dados)
# Feature selection
# Vamos utilizar um modelo linear simples com todas as variáveis para
# determinar quais são as variáveis mais significantes para nosso modelo
# preditivo.
FeaturesLM <- lm(ConsMedio ~ .,
data = dados)
summary(FeaturesLM)
# Podemos identificar que Tamanho do Pneu, Autonomia, Capacidade da Bateria
# e Cambio são estatisticamente relevantes ao nosso modelo.
# Vamos seguir deste ponto para construir nosso modelo base.
# Analisando as Métricas do Modelo Base, verificamos que o Modelo gerou um
# R² = 97,45% e um R² Ajust = 94%, significando que 94% da Variabilidade do
# consumo médio é explicado pelas variáveis que aplicamos.
# Essa informação pode indicar que nosso modelo está com overfitting, porém para
# este momento, apenas queríamos determinar quais variáveis são mais
# significantes, o que nos serviu perfeitamente.
# Porém podemos verificar que os dados estão em diferentes escalas e isso
# pode prejudicar ou tendenciar o funcionamento dos modelos de regressão
# linear. Vamos experimentar regularizar nossa base de dados e rodar
# novamente um modelo de regressão linear para compararmos os resultados.
# Aplicando Padronização ao Dataset
# Criando um função de Padronizar
padronizar <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Primeiramente vamos dividir nosso modelo em dados de treino e teste.
separador <- createDataPartition(y = dados$ConsMedio, p = 0.75,
list = FALSE)
dados_treino <- dados[separador,]
dados_teste <- dados[-separador,]
str(dados_teste)
str(dados_treino)
# Aplicando a Função aos Dados Treino Numéricos
dados_testeNumP <- dados_teste[,!unlist(lapply(dados_teste,
is.factor))]
str(dados_testeNumP)
dados_testeFac <- dados_teste[, unlist(lapply(dados_teste
, is.factor))]
str(dados_testeFac)
dados_treinoNumP <- dados_treino[,!unlist(lapply(dados_treino,
is.factor))]
str(dados_treinoNumP)
dados_treinoFac <- dados_treino[, unlist(lapply(dados_treino
, is.factor))]
str(dados_treinoFac)
dados_testeNumP <- as.data.frame(lapply(dados_testeNumP[,-20]
, padronizar))
dados_testeNumP <- cbind(dados_testeNumP, dados_teste$ConsMedio)
colnames(dados_testeNumP)[20] <- 'ConsMedio'
# Carregando Pacotes
#
library(dplyr)
library(kim)
library(caret)
dados <- as.data.frame(read_csv(name = 'dados_ajustados', head = TRUE,
dirname = 'dados' ))
dim(dados)
dados <- dados[, 5:26]
dim(dados)
str(dados)
dados$Freios <- as.factor(dados$Freios)
dados$Cambio <- as.factor(dados$Cambio)
dados$NumAssentos <- as.factor(dados$NumAssentos)
dados$NumeroPortas <- as.factor(dados$NumeroPortas)
str(dados)
View(dados)
FeaturesLM <- lm(ConsMedio ~ .,
data = dados)
summary(FeaturesLM)
return ((x - min(x)) / (max(x) - min(x)))
padronizar <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
separador <- createDataPartition(y = dados$ConsMedio, p = 0.75,
list = FALSE)
dados_treino <- dados[separador,]
dados_teste <- dados[-separador,]
str(dados_teste)
str(dados_treino)
dados_testeNumP <- dados_teste[,!unlist(lapply(dados_teste,
is.factor))]
str(dados_testeNumP)
dados_testeFac <- dados_teste[, unlist(lapply(dados_teste
, is.factor))]
str(dados_testeFac)
dados_treinoNumP <- dados_treino[,!unlist(lapply(dados_treino,
is.factor))]
str(dados_treinoNumP)
dados_treinoFac <- dados_treino[, unlist(lapply(dados_treino
, is.factor))]
str(dados_treinoFac)
dados_testeNumP <- as.data.frame(lapply(dados_testeNumP[,-18]
, padronizar))
dados_testeNumP <- cbind(dados_testeNumP, dados_teste$ConsMedio)
colnames(dados_testeNumP)[18] <- 'ConsMedio'
str(dados_testeNumP)
dados_treinoNumP <- as.data.frame(lapply(dados_treinoNumP[, -18],
padronizar))
dados_treinoNumP <- cbind(dados_treinoNumP, dados_treino$ConsMedio)
colnames(dados_treinoNumP)[18] <- 'ConsMedio'
str(dados_treinoNumP)
dados_treino_final <- cbind(dados_treinoNumP, dados_treinoFac)
dados_teste_final <- cbind(dados_testeNumP, dados_testeFac)
str(dados_treino_final)
str(dados_teste_final)
FeaturesLMS <- lm(ConsMedio ~ ., data = dados_treino_final)
summary(FeaturesLMS)
dados_prep_teste <- dados_teste_final %>% select(TorqMax, Autonomia, DistEixos,
Largura, BootCap, CapMaxBat,
NumAssentos, ConsMedio)
str(dados_prep_teste)
dados_pre_treino <- dados_treino_final %>% select(TorqMax, Autonomia, DistEixos,
Largura, BootCap, CapMaxBat,
NumAssentos, ConsMedio)
dados_prep_treino <- dados_treino_final %>% select(TorqMax, Autonomia, DistEixos,
Largura, BootCap, CapMaxBat,
NumAssentos, ConsMedio)
str(dados_prep_treino)
write.csv2(dados_prep_treino,file = 'dados/dados_prep_treino.csv')
write.csv2(dados_prep_teste,file = 'dados/dados_prep_teste.csv')
library(forecast)
dados_teste <- read.csv2('dados/dados_prep_teste.csv', header = TRUE)
dim(dados)
str(dados)
dados_treino <- read.csv2('dados/dados_prep_treino.csv', header = TRUE)
str(dados_treino)
dados_teste <- read.csv2('dados/dados_prep_teste.csv', header = TRUE)
str(dados_teste)
summary(is.na(dados_treino))
summary(is.na(dados_teste))
ModeloBase <- lm(ConsMedio ~ ., dados_treino)
summary(ModeloBase)
dados_treino <- read.csv2('dados/dados_prep_treino.csv', header = TRUE)[-1]
str(dados_treino)
dados_teste <- read.csv2('dados/dados_prep_teste.csv', header = TRUE)[-1]
str(dados_teste)
summary(is.na(dados_treino))
summary(is.na(dados_teste))
ModeloBase <- lm(ConsMedio ~ ., dados_treino)
summary(ModeloBase)
# Acurácia do Modelo Base de Treino
accuracy(predict(ModeloBase, dados_treino$ConsMedio), dados_treino$ConsMedio)
# Acurácia do Modelo Base de Treino
prev_treino_ModeloB <- predict(ModeloBase, dados_treino$ConsMedio)
# Acurácia do Modelo Base de Treino
prev_treino_ModeloB <- predict(ModeloBase, dados_treino[-1])
# Acurácia do Modelo Base de Treino
prev_treino_ModeloB <- predict(ModeloBase, dados_treino[-'ConsMedio'])
# Acurácia do Modelo Base de Treino
prev_treino_ModeloB <- predict(ModeloBase, dados_treino[-8])
accuracy(predict(ModeloBase, dados_treino$ConsMedio), dados_treino$ConsMedio)
accuracy(prev_treino_ModeloB, dados_treino$ConsMedio)
Previsao01 <- data.frame(Previsao = predict(ModeloBase, dados_teste[-8]))
Previsao01
accuracy(Previsao01, dados_teste$ConsMedio)
Previsao01 <- predict(ModeloBase, dados_teste[-8])
Previsao01
accuracy(Previsao01, dados_teste$ConsMedio)
ConsumoTeste <- data.frame(Target = dados_teste$ConsMedio)
ConsumoTeste <- dados_teste$ConsMedio
Res_ModeloBase <- data.frame(Residuo = ConsumoTeste$Target - Previsao01)
Res_ModeloBase <- data.frame(Residuo = ConsumoTeste - Previsao01)
FitModeloBase <- data.frame(Target = ConsumoTeste$Target,
Previsao = Previsao01$Previsao,
Residuo = Res_ModeloBase$Previsao)
Res_ModeloBase <- ConsumoTeste - Previsao01
FitModeloBase <- data.frame(Target = ConsumoTeste,
Previsao = Previsao01,
Residuo = Res_ModeloBase)
head(FitModeloBase)
summary(FitModeloBase)
camada1 <- geom_point(shape = 1)
camada2 <- geom_smooth(method = lm, color = 'red', se = FALSE)
ggplot(FitModeloBase, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo Base') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 88,43%')
ggplot(FitModeloBase, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo Base') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 85,12%')
ModeloV02 <- train(ConsMedio ~ ., data = dados_treino[-8], method = 'lm')
summary(ModeloV02)
ModeloV02 <- train(ConsMedio ~ ., data = dados_treino[-8], method = 'lm')
ModeloV02 <- train(ConsMedio ~ ., data = dados_treino, method = 'lm')
summary(ModeloV02)
Previsao02 <- predict(ModeloV02, dados_teste[-8]))
Previsao02 <- predict(ModeloV02, dados_teste[-8])
Previsao02
Res_ModeloV02 <- ConsumoTeste - Previsao02
FitModeloV02 <- data.frame(Target = ConsumoTeste,
Previsao = Previsao02,
Residuo = Res_ModeloV02)
head(FitModeloV02)
summary(FitModeloV02)
camada1 <- geom_point(shape = 1)
camada2 <- geom_smooth(method = lm, color = 'red', se = FALSE)
ggplot(FitModeloV02, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo V02') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 88,43%')
ModeloV03 <- train(ConsMedio ~ ., data = dados_treino, method = 'BstLm')
ModeloV03
Previsao03 <- predict(ModeloV03, dados_teste[-8])
Previsao03
accuracy(Previsao02, dados_teste$ConsMedio)
Res_ModeloV03 <- ConsumoTeste - Previsao03
FitModeloV03 <- data.frame(Target = ConsumoTeste,
Previsao = Previsao03,
Residuo = Res_ModeloV03)
head(FitModeloV03)
summary(FitModeloV03)
ggplot(FitModeloV03, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V03')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 82.87%')
ModeloV04 <- train(ConsMedio ~ ., data = dados_treino, method = 'glmnet')
ModeloV04
Previsao04 <- predict(ModeloV04, dados_teste[-8])
Previsao04
Res_ModeloV04 <- ConsumoTeste - Previsao04
FitModeloV04 <- data.frame(Target = ConsumoTeste,
Previsao = Previsao04,
Residuo = Res_ModeloV04)
head(FitModeloV03)
summary(FitModeloV04)
ggplot(FitModeloV04, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V04')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 77,77%')
# Parte 03 - Pré-Processamento dos Dados
# Neste etapa, vamos aplicar feature selection e definir quais variáveis vamos
# levar em consideração em nosso modelo preditivo base.
# Carregando Pacotes
#
library(dplyr)
library(kim)
library(caret)
# Carregando o Dataset
dados <- as.data.frame(read_csv(name = 'dados_ajustados', head = TRUE,
dirname = 'dados' ))
dim(dados)
dados <- dados[, 5:26]
dim(dados)
str(dados)
dados$Freios <- as.factor(dados$Freios)
dados$Cambio <- as.factor(dados$Cambio)
dados$NumAssentos <- as.factor(dados$NumAssentos)
dados$NumeroPortas <- as.factor(dados$NumeroPortas)
str(dados)
View(dados)
# Feature selection
# Vamos utilizar um modelo linear simples com todas as variáveis para
# determinar quais são as variáveis mais significantes para nosso modelo
# preditivo.
FeaturesLM <- lm(ConsMedio ~ .,
data = dados)
summary(FeaturesLM)
# Parte 03 - Pré-Processamento dos Dados
# Neste etapa, vamos aplicar feature selection e definir quais variáveis vamos
# levar em consideração em nosso modelo preditivo base.
# Carregando Pacotes
#
library(dplyr)
library(kim)
library(caret)
# Carregando o Dataset
dados <- as.data.frame(read_csv(name = 'dados_ajustados', head = TRUE,
dirname = 'dados' ))
dim(dados)
dados <- dados[, 5:26]
dim(dados)
str(dados)
dados$Freios <- as.factor(dados$Freios)
dados$Cambio <- as.factor(dados$Cambio)
dados$NumAssentos <- as.factor(dados$NumAssentos)
dados$NumeroPortas <- as.factor(dados$NumeroPortas)
str(dados)
View(dados)
# Feature selection
# Vamos utilizar um modelo linear simples com todas as variáveis para
# determinar quais são as variáveis mais significantes para nosso modelo
# preditivo.
FeaturesLM <- lm(ConsMedio ~ .,
data = dados)
summary(FeaturesLM)
# Podemos identificar que Autonomia, Cambio, Distância entre Eixos,
# Numero de Assentos, Tamanho do Pneu e Capacidade do porta-malas
# são estatisticamente relevantes ao nosso modelo.
# Vamos seguir deste ponto para construir nosso modelo base.
# Analisando as Métricas do Modelo Base, verificamos que o Modelo gerou um
# R² = 98,22% e um R² Ajust = 95,45%, significando que 95% da Variabilidade do
# consumo médio é explicado pelas variáveis que aplicamos.
# Essa informação pode indicar que nosso modelo está com overfitting, porém para
# este momento, apenas queríamos determinar quais variáveis são mais
# significantes, o que nos serviu perfeitamente.
# Porém podemos verificar que os dados estão em diferentes escalas e isso
# pode prejudicar ou tendenciar o funcionamento dos modelos de regressão
# linear. Vamos experimentar padronizar nossa base de dados e rodar
# novamente um modelo de regressão linear para compararmos os resultados.
# Aplicando Padronização ao Dataset
# Criando um função de Padronizar
padronizar <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Primeiramente vamos dividir nosso modelo em dados de treino e teste.
separador <- createDataPartition(y = dados$ConsMedio, p = 0.75,
list = FALSE)
dados_treino <- dados[separador,]
dados_teste <- dados[-separador,]
str(dados_teste)
str(dados_treino)
# Aplicando a Função aos Dados Treino Numéricos
dados_testeNumP <- dados_teste[,!unlist(lapply(dados_teste,
is.factor))]
str(dados_testeNumP)
dados_testeFac <- dados_teste[, unlist(lapply(dados_teste
, is.factor))]
str(dados_testeFac)
dados_treinoNumP <- dados_treino[,!unlist(lapply(dados_treino,
is.factor))]
str(dados_treinoNumP)
dados_treinoFac <- dados_treino[, unlist(lapply(dados_treino
, is.factor))]
str(dados_treinoFac)
dados_testeNumP <- as.data.frame(lapply(dados_testeNumP[,-18]
, padronizar))
dados_testeNumP <- cbind(dados_testeNumP, dados_teste$ConsMedio)
colnames(dados_testeNumP)[18] <- 'ConsMedio'
str(dados_testeNumP)
dados_treinoNumP <- as.data.frame(lapply(dados_treinoNumP[, -18],
padronizar))
dados_treinoNumP <- cbind(dados_treinoNumP, dados_treino$ConsMedio)
colnames(dados_treinoNumP)[18] <- 'ConsMedio'
str(dados_treinoNumP)
# Unificando os Data Frames
dados_treino_final <- cbind(dados_treinoNumP, dados_treinoFac)
dados_teste_final <- cbind(dados_testeNumP, dados_testeFac)
str(dados_treino_final)
str(dados_teste_final)
# Reavaliando as Variáveis de Maior Significância
FeaturesLMS <- lm(ConsMedio ~ ., data = dados_treino_final)
summary(FeaturesLMS)
FeaturesLMS <- lm(ConsMedio ~ ., data = dados_treino_final)
summary(FeaturesLMS)
dados_final <- rbind(dados_treino_final, dados_teste_final)
FeaturesLMS <- lm(ConsMedio ~ ., data = dados_final)
summary(FeaturesLMS)
dados_prep_teste <- dados_teste_final %>% select(CapBat, Autonomia, DistEixos,
CapMax, Cambio, NumAssentos,
ConsMedio)
str(dados_prep_teste)
dados_prep_treino <- dados_treino_final %>% select(CapBat, Autonomia, DistEixos,
CapMax, Cambio, NumAssentos,
ConsMedio)
str(dados_prep_treino)
write.csv2(dados_prep_treino,file = 'dados/dados_prep_treino.csv')
write.csv2(dados_prep_teste,file = 'dados/dados_prep_teste.csv')
ModeloBase <- lm(ConsMedio ~ ., dados_treino)
summary(ModeloBase)
# Parte 04 - Modelagem Preditiva
# Neste etapa, vamos criar modelos de machine learning e analisar as métricas
# de cada modelo e definir qual realiza previsões com mais eficiência,
# utilizando o dataset preparado e levando em consideração nosso modelo
# preditivo base.
# Carregando Pacotes
library(dplyr)
library(caret)
library(ggplot2)
library(forecast)
# Carregando o Dataset
dados_treino <- read.csv2('dados/dados_prep_treino.csv', header = TRUE)[-1]
str(dados_treino)
dados_teste <- read.csv2('dados/dados_prep_teste.csv', header = TRUE)[-1]
str(dados_teste)
summary(is.na(dados_treino))
summary(is.na(dados_teste))
# Construindo nosso Modelo Base
# Vamos utilizar a função lm() para construir nosso modelo base, sendo o
# algoritmo mais simples que conhecemos.
ModeloBase <- lm(ConsMedio ~ ., dados_treino)
summary(ModeloBase)
# Acurácia do Modelo Base de Treino
prev_treino_ModeloB <- predict(ModeloBase, dados_treino[-8])
accuracy(prev_treino_ModeloB, dados_treino$ConsMedio)
# Testando e Avaliando o Modelo
Previsao01 <- predict(ModeloBase, dados_teste[-8])
Previsao01
# Analisando a Acurárcia do Teste para o Modelo Base
accuracy(Previsao01, dados_teste$ConsMedio)
# Obtivemos uma acurácia relativamente mais alta que em treino
# no valor de RMSE 2.907. !! Ponto de Atenção
# Analisando o resíduo do modelo
ConsumoTeste <- dados_teste$ConsMedio
Res_ModeloBase <- ConsumoTeste - Previsao01
FitModeloBase <- data.frame(Target = ConsumoTeste,
Previsao = Previsao01,
Residuo = Res_ModeloBase)
head(FitModeloBase)
summary(FitModeloBase)
# Scatter Plot Comparativo
camada1 <- geom_point(shape = 1)
camada2 <- geom_smooth(method = lm, color = 'red', se = FALSE)
ggplot(FitModeloBase, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo Base') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 92,67 RSME = 1.027,12%')
ModeloV02 <- train(ConsMedio ~ ., data = dados_treino, method = 'lm')
summary(ModeloV02)
Previsao02 <- predict(ModeloV02, dados_teste[-8])
Previsao02
accuracy(Previsao02, dados_teste$ConsMedio)
ggplot(FitModeloBase, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo Base') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 92,67 RSME = 2.22%')
# Construindo Modelo Versão 02
# Para este modelo, utilizaremo o pacote Caret com o método de Regressão
# Linear, sem Trainig Control e Tuning.
ModeloV02 <- train(ConsMedio ~ ., data = dados_treino, method = 'lm')
summary(ModeloV02)
# Podemos reparar que obtivemos um R² de 92,67%, mesmo valor do modelo base.
# Vamos realizar a Previsão de teste e avaliar
# graficamente.
Previsao02 <- predict(ModeloV02, dados_teste[-8])
Previsao02
accuracy(Previsao02, dados_teste$ConsMedio)
# Mesma acurácia do modelo base RMSE 2.907
# Analisando o resíduo do modelo
Res_ModeloV02 <- ConsumoTeste - Previsao02
FitModeloV02 <- data.frame(Target = ConsumoTeste,
Previsao = Previsao02,
Residuo = Res_ModeloV02)
head(FitModeloV02)
summary(FitModeloV02)
# Scatter Plot Comparativo
camada1 <- geom_point(shape = 1)
camada2 <- geom_smooth(method = lm, color = 'red', se = FALSE)
ggplot(FitModeloV02, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo V02') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 92,67 RSME = 2.22%')
ModeloV03 <- train(ConsMedio ~ ., data = dados_treino, method = 'BstLm')
ModeloV03
Previsao03 <- predict(ModeloV03, dados_teste[-8])
Previsao03
# Construindo Modelo V03
# Para este modelo vamos alterar o método de Regressão Linear para Boosted
# Linear Regression e analisar os resultados.
# Utilizaremos o mesmo pacote Caret.
ModeloV03 <- train(ConsMedio ~ ., data = dados_treino, method = 'BstLm')
ModeloV03
Previsao03 <- predict(ModeloV03, dados_teste[-8])
Previsao03
# Acurácia de RMSE 3.34 e um R² de 65.12%, obtendo uma performance
# inferior em R² e acurácia
# Analisando o resíduo do modelo
Res_ModeloV03 <- ConsumoTeste - Previsao03
FitModeloV03 <- data.frame(Target = ConsumoTeste,
Previsao = Previsao03,
Residuo = Res_ModeloV03)
head(FitModeloV03)
summary(FitModeloV03)
# Scatter Plot Comparativo
ggplot(FitModeloV03, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V03')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 65,12% RSME = 3.34')
ggplot(FitModeloV03, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V03')+
annotate(geom = 'text', x = 20, y = 25, label = 'R² = 65,12% RSME = 3.34')
ModeloV04 <- train(ConsMedio ~ ., data = dados_treino, method = 'glmnet')
ModeloV04
# Tivemos uma piora drástica do R² em relação ao Modelo V03, porém ainda
# assim nosso modelo base é melhor em relação a métrica de varibilidade
# das variáveis em relação a variável resposta.
Previsao04 <- predict(ModeloV04, dados_teste[-8])
Previsao04
# Analisando o resíduo do modelo
Res_ModeloV04 <- ConsumoTeste - Previsao04
FitModeloV04 <- data.frame(Target = ConsumoTeste,
Previsao = Previsao04,
Residuo = Res_ModeloV04)
head(FitModeloV03)
summary(FitModeloV04)
ggplot(FitModeloV04, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V04')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 84,39% RMSE = 1.66')
