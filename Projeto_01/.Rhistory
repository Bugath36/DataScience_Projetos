Previsao04
Res_ModeloV04 <- data.frame(Residuo = ConsumoTeste$Target - Previsao04$Previsao)
FitModeloV04 <- data.frame(Target = ConsumoTeste$Target,
Previsao = Previsao04$Previsao,
Residuo = Res_ModeloV04$Residuo)
head(FitModeloV03)
ggplot(FitModeloV04, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V03')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 84,32%')
ggplot(FitModeloV04, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V04')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 84,32%')
summary(FitModeloV04)
summary(FitModeloV03)
summary(FitModeloV02)
summary(FitModeloBase)
# Carregando e Ajustando o Dataset
getwd()
?read_xlsx
dadosv00 <- read_xlsx('dados/fev_dataset.xlsx', na = 'NaN')
library(readxl)
library(thinkr)
library(usefun)
library(Amelia)
getwd()
dadosv00 <- read_xlsx('dados/fev_dataset.xlsx', na = 'NaN')
View(dadosv00)
dim(dadosv00)
str(dadosv00)
# Convertendo o objeto para DataFrame
dadosv00 <- as.data.frame(dadosv00)
# Verificando Dados NaN
summary(is.na(dadosv00))
colSums(is.na(dadosv00))
missmap(dadosv00)
# Convertendo o objeto para DataFrame
dadosv00 <- as.data.frame(dadosv00)
# Verificando Dados NaN
summary(is.na(dadosv00))
colSums(is.na(dadosv00))
missmap(dadosv00)
# Eliminando os dados Na
dadosv01 <- na.omit(dadosv00)
summary(is.na(dadosv01))
colSums(is.na(dadosv01))
missmap(dadosv01)
# Renomeando as Colunas
nomesCol <- c('Carro', 'Fabricante', 'Modelo', 'PrecoMin', 'Potencia',
'TorqMax', 'Freios','Cambio', 'CapBat', 'Autonomia',
'DistEixos', 'Comprimento', 'Largura', 'Altura', 'PesoVazio',
'PesoCheio', 'CapMax', 'NumAssentos', 'NumeroPortas',
'TamPneu','VelMax', 'BootCap', 'Acc', 'CapMaxBat',
'ConsMedio')
colnames(dadosv01) <- nomesCol
View(dadosv01)
# Realizando Label Encoding das Variáveis Categóricas
# Como pretendemos criar um modelo de regressão, precisamos identificar
# quais variáveis categoricas vamos transformar em numericas.
# Temos como Variáveis Categoricas: Carro, Fabricante, Modelo , Freios
# e Cambio. Como carro e modelo possuem muitos fatores, vamos descartar
# neste momento. Vamos manter Fabricante, Freios e Cambio e transformar
# em variáveis numericas.
dadosv01$Fabricante <- as.numeric(as.factor(dadosv01$Fabricante))
# Dicionário da Variável Fabricante
# Audi = 1, BMW = 2, Citroen = 3, DS = 4, Honda = 5, Hyundai = 6,
# Jaguar = 7, Kia = 8, Mazda = 9, Mercedes-Benz = 10, Mini = 11,
# Nissan = 12, Opel = 13, Peugeot = 14,Porshe = 15, Renault = 16,
# Skoda = 17, Smart = 18 e Volkswagen = 19
dadosv01$Freios <- as.numeric(as.factor(dadosv01$Freios))
# Dicionário da Variável Fabricante
# Freio a Disco nas 4 rodas = 1
# Freio a Disco na Dianteira e Tambor na traseira = 2
dadosv01$Cambio <- as.numeric(as.factor(dadosv01$Cambio))
# Dicionário da Variável Fabricante
# 4WD = 3
# 2WD(rear) = 2
# 2WD(front) = 1
str(dadosv01)
file = 'dados/dados_ajustados.csv'
save_df_to_file(dadosv01, file = file)
# Parte 02 - Projeto_01 -> Previsão de Consumo de Energia em Carros Elétricos
# Nesta parte vamos fazer algumas análises exploratórias, com o objetivo de
# entender os dados e como eles se relacionam.
getwd()
# Pacotes
library(kim)
library(plotly)
library(ggplot2)
library(dplyr)
library(corrplot)
library(GGally)
library(gridExtra)
# Verificando e ajustando os tipos de variáveis
dados <- as.data.frame(read_csv(name = 'dados_ajustados', head = TRUE,
dirname = 'dados' ))
dados <- dados[, -1]
dados$Fabricante <- as.factor(dados$Fabricante)
dados$Freios <- as.factor(dados$Freios)
dados$Cambio <- as.factor(dados$Cambio)
str(dados)
View(dados)
# As demais variáveis estão com seus devido tipos corretos, então vamos
# manter sem demais alterações.
# Análise Exploratória dos Dados
summary(dados)
# Podemos reparar que a Média e a Mediana possuem valores próximos em todas
# as variáveis numéricas, o que nos indica uma possível distribuição normal.
# Vamos separar as Variáveis em Numérias, Categoricas e Resposta para
# analisarmos de forma separada.
VarNum <- dados %>% select(c(4:6), c(9:24))
VarCat <- dados %>% select(c(1:3), c(7:8))
VarResp <- dados$ConsMedio
# Variável Resposta
summary(VarResp) # Min. 13.10 / 1st Qu.15.60 / Median 16.88 / Mean 18.61
#  3rd Qu. 22.94 / Max. 27.55
diff(range(VarResp)) # 14.45
sd(VarResp) # 4.134293
var(VarResp) # 17.09238
hist(VarResp, main = 'Distribuição do Consumo Médio em Carros Elétricos',
xlab = 'Consumo de Energia [kW/h]')
# Alguns dados estão discrepantes, com valores muito acima da média dos
# dados, talvez um outlier, que poderemos comprovar com um boxplot.
# Não podemos afirmar que temos uma distribuição normal nos dados, mas
# podemos realizar um teste estatístico de normalidade chamado Shapiro-test
# Hipótese H0 -> Consideramos que os dados são normalmente distribuídos
# Hipótese H1 -> Não podemos considerar que os dados são normalmente
# distribuidos
# Se p-value > que 0.05 não rejeitamos a H0
# Se p-value < 0.05 então rejeitamos H0.
shapiro.test(VarResp)
# Aplicamos o teste e p-value < 0.05, portanto rejeitamos H0 e não
# podemos considerar que a variável resposta possua uma distribuição
# normal.
boxplot(VarResp, main = 'Consumo Médio em Carros Elétricos')
# Verificamos que não temos dados outliers, mantendo assim os dados com um
# padrão razoável a ser analisado.
# Variáveis Independentes Numéricas
summary(VarNum)
dim(VarNum)
colnames(VarNum)
# Multi-Hitogramas de cada Variável
VarNum01 <- ggplot(VarNum) + geom_histogram(aes(x = PrecoMin))
VarNum02 <- ggplot(VarNum) + geom_histogram(aes(x = Potencia))
VarNum03 <- ggplot(VarNum) + geom_histogram(aes(x = TorqMax))
VarNum04 <- ggplot(VarNum) + geom_histogram(aes(x = CapBat))
VarNum05 <- ggplot(VarNum) + geom_histogram(aes(x = Autonomia))
VarNum06 <- ggplot(VarNum) + geom_histogram(aes(x = DistEixos))
VarNum07 <- ggplot(VarNum) + geom_histogram(aes(x = Comprimento))
VarNum08 <- ggplot(VarNum) + geom_histogram(aes(x = Largura))
VarNum09 <- ggplot(VarNum) + geom_histogram(aes(x = Altura))
VarNum10 <- ggplot(VarNum) + geom_histogram(aes(x = PesoVazio))
VarNum11 <- ggplot(VarNum) + geom_histogram(aes(x = PesoCheio))
VarNum12 <- ggplot(VarNum) + geom_histogram(aes(x = CapMax))
VarNum13 <- ggplot(VarNum) + geom_histogram(aes(x = NumAssentos))
VarNum14 <- ggplot(VarNum) + geom_histogram(aes(x = NumeroPortas))
VarNum15 <- ggplot(VarNum) + geom_histogram(aes(x = TamPneu))
VarNum16 <- ggplot(VarNum) + geom_histogram(aes(x = VelMax))
VarNum17 <- ggplot(VarNum) + geom_histogram(aes(x = BootCap))
VarNum18 <- ggplot(VarNum) + geom_histogram(aes(x = Acc))
VarNum19 <- ggplot(VarNum) + geom_histogram(aes(x = CapMaxBat))
grid.arrange(VarNum01, VarNum02, VarNum03, VarNum04, VarNum05,
VarNum06, VarNum07, VarNum08, VarNum09, VarNum10,
VarNum11, VarNum12, VarNum13, VarNum14, VarNum15,
VarNum16, VarNum17, VarNum18,VarNum19)
# Análise de Multicolinearidade
corrplot(cor(cbind(VarNum, VarResp)))
# Podemos identificar aqui excessiva correlação entre variáveis, o que
# causa confusão durante nossa modelagem preditiva.
# Também podemos ver que individualmente muitas variáveis se
# correlacionam com nossa Variável resposta, o que comprova a
# multicolinearidade.
# Scatterplots de Cada Variável Numérica Dependente e a Variável Resposta
DadosIntResp <-dados %>% select(c(4:6), c(9:25))
Multiplot <- function(DadosIntResp, mapping, method = "loess", ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point()+
geom_smooth(method = method, ...)
p
}
ggpairs(DadosIntResp, lower = list(continous = Multiplot))
# Claramente temos muitas variáveis numéricas se correlacionando e
# correlacionando com a variável resposta. Precisamos realizar uma
# seleção de variáveis mais significantes e faremos isso usando uma
# algoritmo de machine learning logo em seguida.
# Variáveis Independentes Categóricas
prop.table(table(VarCat$Freios))*100
prop.table(table(VarCat$Cambio))*100
media_por_tipo_de_freio = dados %>% group_by(Freios) %>%
summarise(avg_consumo = mean(ConsMedio))
media_por_tipo_de_tracao = dados %>% group_by(Cambio) %>%
summarise(avg_consumo = mean(ConsMedio))
barplot(media_por_tipo_de_freio$avg_consumo,
names.arg = media_por_tipo_de_freio$Freios,
main = 'Média de Consumo por Tipo de Freio')
barplot(media_por_tipo_de_tracao$avg_consumo,
names.arg = media_por_tipo_de_tracao$Cambio,
main = 'Média de Consumo por Tipo de Tração')
# É relevante perceber que para o Tipo de Freio, temos uma média de consumo
# de energia menor em freios a disco duplos.
# Quando avaliamos da mesma forma a tração, percebemos diferença no consumo
# apenas em 4WD, com um consume médio maior que com 2WD, sendo indiferente
# a tração ser dianteira ou traseira.
# As categorias Modelo, Marca e Nome não são importantes para nossa análise
# e foram automaticamente descartadas.
# Finalizamos nossa Exploração dos Dados e estamos prontos para iniciar
# a etapa de Preparação dos dados para enfim Construirmos nosso modelo
# Preditivo.
# Variável Resposta
summary(VarResp) # Min. 13.10 / 1st Qu.15.60 / Median 16.88 / Mean 18.61
#  3rd Qu. 22.94 / Max. 27.55
diff(range(VarResp)) # 14.45
sd(VarResp) # 4.134293
var(VarResp) # 17.09238
hist(VarResp, main = 'Distribuição do Consumo Médio em Carros Elétricos',
xlab = 'Consumo de Energia [kW/h]')
skewness(VarResp)
hist(VarResp, main = 'Distribuição do Consumo Médio em Carros Elétricos',
xlab = 'Consumo de Energia [kW/h]')
boxplot(VarResp, main = 'Distribuição do Consumo Médio em Carros Elétricos',
xlab = 'Consumo de Energia [kW/h]')
shapiro.test(VarResp)
boxplot(VarResp, main = 'Consumo Médio em Carros Elétricos')
boxplot(VarResp, main = 'Consumo Médio em Carros Elétricos',
xlab = 'Consumo de Energia [kW/h]')
summary(VarNum)
dim(VarNum)
colnames(VarNum)
summary(VarNum)
dim(VarNum)
colnames(VarNum)
# Multi-Hitogramas de cada Variável
VarNum01 <- ggplot(VarNum) + geom_histogram(aes(x = PrecoMin))
VarNum02 <- ggplot(VarNum) + geom_histogram(aes(x = Potencia))
VarNum03 <- ggplot(VarNum) + geom_histogram(aes(x = TorqMax))
VarNum04 <- ggplot(VarNum) + geom_histogram(aes(x = CapBat))
VarNum05 <- ggplot(VarNum) + geom_histogram(aes(x = Autonomia))
VarNum06 <- ggplot(VarNum) + geom_histogram(aes(x = DistEixos))
VarNum07 <- ggplot(VarNum) + geom_histogram(aes(x = Comprimento))
VarNum08 <- ggplot(VarNum) + geom_histogram(aes(x = Largura))
VarNum09 <- ggplot(VarNum) + geom_histogram(aes(x = Altura))
VarNum10 <- ggplot(VarNum) + geom_histogram(aes(x = PesoVazio))
VarNum11 <- ggplot(VarNum) + geom_histogram(aes(x = PesoCheio))
VarNum12 <- ggplot(VarNum) + geom_histogram(aes(x = CapMax))
VarNum13 <- ggplot(VarNum) + geom_histogram(aes(x = NumAssentos))
VarNum14 <- ggplot(VarNum) + geom_histogram(aes(x = NumeroPortas))
VarNum15 <- ggplot(VarNum) + geom_histogram(aes(x = TamPneu))
VarNum16 <- ggplot(VarNum) + geom_histogram(aes(x = VelMax))
VarNum17 <- ggplot(VarNum) + geom_histogram(aes(x = BootCap))
VarNum18 <- ggplot(VarNum) + geom_histogram(aes(x = Acc))
VarNum19 <- ggplot(VarNum) + geom_histogram(aes(x = CapMaxBat))
grid.arrange(VarNum01, VarNum02, VarNum03, VarNum04, VarNum05,
VarNum06, VarNum07, VarNum08, VarNum09, VarNum10,
VarNum11, VarNum12, VarNum13, VarNum14, VarNum15,
VarNum16, VarNum17, VarNum18,VarNum19)
# Parte 02 - Projeto_01 -> Previsão de Consumo de Energia em Carros Elétricos
# Nesta parte vamos fazer algumas análises exploratórias, com o objetivo de
# entender os dados e como eles se relacionam.
getwd()
# Pacotes
library(kim)
library(plotly)
library(ggplot2)
library(dplyr)
library(corrplot)
library(GGally)
library(gridExtra)
# Verificando e ajustando os tipos de variáveis
dados <- as.data.frame(read_csv(name = 'dados_ajustados', head = TRUE,
dirname = 'dados' ))
dados <- dados[, -1]
dados$Fabricante <- as.factor(dados$Fabricante)
dados$Freios <- as.factor(dados$Freios)
dados$Cambio <- as.factor(dados$Cambio)
str(dados)
View(dados)
# As demais variáveis estão com seus devido tipos corretos, então vamos
# manter sem demais alterações.
# Análise Exploratória dos Dados
summary(dados)
# Podemos reparar que a Média e a Mediana possuem valores próximos em todas
# as variáveis numéricas, o que nos indica uma possível distribuição normal.
# Vamos separar as Variáveis em Numérias, Categoricas e Resposta para
# analisarmos de forma separada.
VarNum <- dados %>% select(c(4:6), c(9:24))
VarCat <- dados %>% select(c(1:3), c(7:8))
VarResp <- dados$ConsMedio
# Variável Resposta
summary(VarResp) # Min. 13.10 / 1st Qu.15.60 / Median 16.88 / Mean 18.61
#  3rd Qu. 22.94 / Max. 27.55
skewness(VarResp)
diff(range(VarResp)) # 14.45
sd(VarResp) # 4.134293
var(VarResp) # 17.09238
hist(VarResp, main = 'Distribuição do Consumo Médio em Carros Elétricos',
xlab = 'Consumo de Energia [kW/h]')
# Alguns dados estão discrepantes, com valores muito acima da mediana dos
# dados, talvez um outlier, que poderemos comprovar com um boxplot.
# Não podemos afirmar que temos uma distribuição normal nos dados, mas
# podemos realizar um teste estatístico de normalidade chamado Shapiro-test
# Hipótese H0 -> Consideramos que os dados são normalmente distribuídos
# Hipótese H1 -> Não podemos considerar que os dados são normalmente
# distribuidos
# Se p-value > que 0.05 não rejeitamos a H0
# Se p-value < 0.05 então rejeitamos H0.
shapiro.test(VarResp)
# Aplicamos o teste e p-value < 0.05, portanto rejeitamos H0 e não
# podemos considerar que a variável resposta possua uma distribuição
# normal.
boxplot(VarResp, main = 'Consumo Médio em Carros Elétricos',
xlab = 'Consumo de Energia [kW/h]')
# Verificamos que não temos dados outliers, mantendo assim os dados com um
# padrão razoável a ser analisado.
# Variáveis Independentes Numéricas
summary(VarNum)
dim(VarNum)
colnames(VarNum)
# Multi-Hitogramas de cada Variável
VarNum01 <- ggplot(VarNum) + geom_histogram(aes(x = PrecoMin))
VarNum02 <- ggplot(VarNum) + geom_histogram(aes(x = Potencia))
VarNum03 <- ggplot(VarNum) + geom_histogram(aes(x = TorqMax))
VarNum04 <- ggplot(VarNum) + geom_histogram(aes(x = CapBat))
VarNum05 <- ggplot(VarNum) + geom_histogram(aes(x = Autonomia))
VarNum06 <- ggplot(VarNum) + geom_histogram(aes(x = DistEixos))
VarNum07 <- ggplot(VarNum) + geom_histogram(aes(x = Comprimento))
VarNum08 <- ggplot(VarNum) + geom_histogram(aes(x = Largura))
VarNum09 <- ggplot(VarNum) + geom_histogram(aes(x = Altura))
VarNum10 <- ggplot(VarNum) + geom_histogram(aes(x = PesoVazio))
VarNum11 <- ggplot(VarNum) + geom_histogram(aes(x = PesoCheio))
VarNum12 <- ggplot(VarNum) + geom_histogram(aes(x = CapMax))
VarNum13 <- ggplot(VarNum) + geom_histogram(aes(x = NumAssentos))
VarNum14 <- ggplot(VarNum) + geom_histogram(aes(x = NumeroPortas))
VarNum15 <- ggplot(VarNum) + geom_histogram(aes(x = TamPneu))
VarNum16 <- ggplot(VarNum) + geom_histogram(aes(x = VelMax))
VarNum17 <- ggplot(VarNum) + geom_histogram(aes(x = BootCap))
VarNum18 <- ggplot(VarNum) + geom_histogram(aes(x = Acc))
VarNum19 <- ggplot(VarNum) + geom_histogram(aes(x = CapMaxBat))
grid.arrange(VarNum01, VarNum02, VarNum03, VarNum04, VarNum05,
VarNum06, VarNum07, VarNum08, VarNum09, VarNum10,
VarNum11, VarNum12, VarNum13, VarNum14, VarNum15,
VarNum16, VarNum17, VarNum18,VarNum19)
# Análise de Multicolinearidade
corrplot(cor(cbind(VarNum, VarResp)))
# Scatterplots de Cada Variável Numérica Dependente e a Variável Resposta
DadosIntResp <-dados %>% select(c(4:6), c(9:25))
Multiplot <- function(DadosIntResp, mapping, method = "loess", ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point()+
geom_smooth(method = method, ...)
p
}
ggpairs(DadosIntResp, lower = list(continous = Multiplot))
prop.table(table(VarCat$Freios))*100
prop.table(table(VarCat$Cambio))*100
media_por_tipo_de_freio = dados %>% group_by(Freios) %>%
summarise(avg_consumo = mean(ConsMedio))
media_por_tipo_de_tracao = dados %>% group_by(Cambio) %>%
summarise(avg_consumo = mean(ConsMedio))
barplot(media_por_tipo_de_freio$avg_consumo,
names.arg = media_por_tipo_de_freio$Freios,
main = 'Média de Consumo por Tipo de Freio')
barplot(media_por_tipo_de_tracao$avg_consumo,
names.arg = media_por_tipo_de_tracao$Cambio,
main = 'Média de Consumo por Tipo de Tração')
# Carregando Pacotes
#
library(dplyr)
library(kim)
# Carregando o Dataset
dados <- as.data.frame(read_csv(name = 'dados_ajustados', head = TRUE,
dirname = 'dados' ))
dim(dados)
dados <- dados[, 5:26]
dim(dados)
View(dados)
FeaturesLM <- lm(ConsMedio ~ .,
data = dados)
summary(FeaturesLM)
FeaturesLM <- lm(ConsMedio ~ .,
data = dados)
summary(FeaturesLM)
# Aplicando Regularização ao Dataset
# Criando um função de normalização
normalizar <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando a Função as Variáveis do Modelo
dados_MinMax <- as.data.frame(lapply(dados[-22], normalizar))
dados_MinMax <- dados_MinMax %>% cbind(dados$ConsMedio)
colnames(dados_MinMax)[22] <- 'ConsMedio'
View(dados_MinMax)
str(dados_MinMax)
# Reavaliando as Variáveis de Maior Significância
FeaturesLMS <- lm(ConsMedio ~ ., data = dados_MinMax)
summary(FeaturesLMS)
# Aplicando Regularização ao Dataset
# Criando um função de normalização
normalizar <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando a Função as Variáveis do Modelo
dados_MinMax <- as.data.frame(lapply(dados[-22], normalizar))
dados_MinMax <- dados_MinMax %>% cbind(dados$ConsMedio)
colnames(dados_MinMax)[22] <- 'ConsMedio'
View(dados_MinMax)
str(dados_MinMax)
# Reavaliando as Variáveis de Maior Significância
FeaturesLMS <- lm(ConsMedio ~ ., data = dados_MinMax)
summary(FeaturesLMS)
# Parte 04 - Modelagem Preditiva
# Neste etapa, vamos criar modelos de machine learning e analisar as métricas
# de cada modelo e definir qual realiza previsões com mais eficiência,
# utilizando o dataset preparado e levando em consideração nosso modelo
# preditivo base.
# Carregando Pacotes
library(dplyr)
library(caret)
library(ggplot2)
# Carregando o Dataset
dados <- read.csv2('dados/dados_preparados.csv', header = TRUE)
dim(dados)
summary(is.na(dados))
dados <- dados[-1]
str(dados)
View(dados)
# Primeiramente vamos dividir nosso modelo em dados de treino e teste.
separador <- createDataPartition(y = dados$ConsMedio, p = 0.75,
list = FALSE)
dados_treino <- dados[separador,]
dados_teste <- dados[-separador, -5]
View(dados_teste)
View(dados_treino)
ModeloBase <- lm(ConsMedio ~ ., dados_treino)
summary(ModeloBase)
ModeloBase <- lm(ConsMedio ~ ., dados_treino)
summary(ModeloBase)
# Testando e Avaliando o Modelo
Previsao01 <- data.frame(Previsao = predict(ModeloBase, dados_teste))
Previsao01
# Analisando o resíduo do modelo
ConsumoTeste <- data.frame(Target = dados[-separador, 5])
Res_ModeloBase <- data.frame(Residuo = ConsumoTeste$Target - Previsao01)
FitModeloBase <- data.frame(Target = ConsumoTeste$Target,
Previsao = Previsao01$Previsao,
Residuo = Res_ModeloBase$Previsao)
head(FitModeloBase)
summary(FitModeloBase)
# Scatter Plot Comparativo
camada1 <- geom_point(shape = 1)
camada2 <- geom_smooth(method = lm, color = 'red', se = FALSE)
ggplot(FitModeloBase, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo Base') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 88,43%')
ModeloV02 <- train(ConsMedio ~ ., data = dados_treino, method = 'lm')
summary(ModeloV02)
Previsao02 <- data.frame(Previsao = predict(ModeloV02, dados_teste))
Previsao02
# Analisando o resíduo do modelo
Res_ModeloV02 <- data.frame(Residuo = ConsumoTeste$Target - Previsao02$Previsao)
FitModeloV02 <- data.frame(Target = ConsumoTeste$Target,
Previsao = Previsao02$Previsao,
Residuo = Res_ModeloV02$Residuo)
head(FitModeloV02)
summary(FitModeloV02)
# Scatter Plot Comparativo
camada1 <- geom_point(shape = 1)
camada2 <- geom_smooth(method = lm, color = 'red', se = FALSE)
ggplot(FitModeloV02, aes(x = Previsao, y = Target)) + camada1 + camada2 +
ggtitle('Performance do Modelo V02') + annotate(geom = 'text', x = 17,
y = 25,
label = 'R² = 88,43%')
ModeloV03 <- train(ConsMedio ~ ., data = dados_treino, method = 'BstLm')
ModeloV03
Previsao03 <- data.frame(Previsao = predict(ModeloV03, dados_teste))
Previsao03
# Analisando o resíduo do modelo
Res_ModeloV03 <- data.frame(Residuo = ConsumoTeste$Target - Previsao03$Previsao)
FitModeloV03 <- data.frame(Target = ConsumoTeste$Target,
Previsao = Previsao03$Previsao,
Residuo = Res_ModeloV03$Residuo)
head(FitModeloV03)
summary(FitModeloV03)
ggplot(FitModeloV03, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V03')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 63,64%')
ModeloV04 <- train(ConsMedio ~ ., data = dados_treino, method = 'glmnet')
ModeloV04
Previsao04 <- data.frame(Previsao = predict(ModeloV04, dados_teste))
Previsao04
# Analisando o resíduo do modelo
Res_ModeloV04 <- data.frame(Residuo = ConsumoTeste$Target - Previsao04$Previsao)
FitModeloV04 <- data.frame(Target = ConsumoTeste$Target,
Previsao = Previsao04$Previsao,
Residuo = Res_ModeloV04$Residuo)
head(FitModeloV03)
summary(FitModeloV04)
ggplot(FitModeloV04, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V04')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 84,32%')
ggplot(FitModeloV04, aes(x = Previsao, y = Target)) +
geom_point(shape = 1) +
geom_smooth(method = lm, color = 'red', se = FALSE) +
ggtitle('Performance do Modelo V04')+
annotate(geom = 'text', x = 17, y = 25, label = 'R² = 83%')
